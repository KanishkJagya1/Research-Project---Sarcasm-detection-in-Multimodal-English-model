# Research Project - Sarcasm Detection in Multimodal English Model

## Overview

This repository contains my ongoing research and implementations on sarcasm detection in multimodal datasets. The primary focus is on leveraging various multimodal fusion techniques to enhance sarcasm detection accuracy. Below, you'll find a collection of relevant research papers, datasets, and my current progress.

## Table of Contents

1. [Introduction](#introduction)
2. [Research Papers](#research-papers)
   - [Multi-Modal Sarcasm Detection](#multi-modal-sarcasm-detection)
   - [Attention-Based Methods](#attention-based-methods)
   - [Sentiment-Aware Fusion](#sentiment-aware-fusion)
3. [Datasets](#datasets)
4. [Current Progress](#current-progress)
5. [Future Work](#future-work)
6. [References](#references)

## Introduction

Sarcasm detection in multimodal datasets involves the use of both textual and visual features to identify sarcasm more accurately. This research aims to explore various fusion models and methodologies to improve the detection of sarcasm in multimodal contexts.

## Research Papers

### Multi-Modal Sarcasm Detection

1. **Multi-modal sarcasm detection based on Multi-Channel Enhanced Fusion model**
   - GitHub Link: [https://github.com/headacheboy/data-of-multimodal-sarcasm-detection](https://github.com/headacheboy/data-of-multimodal-sarcasm-detection)
   - Summary: This paper proposes a multi-channel enhanced fusion model to detect sarcasm by integrating textual and visual features.

2. **An Attention-based, Context-aware Multimodal Fusion Method for Sarcasm Detection using Inter-modality Inconsistency**
   - GitHub Link: [https://github.com/XDU-AI-LYYLab/MultimodalSarcasmDetection](https://github.com/XDU-AI-LYYLab/MultimodalSarcasmDetection)
   - Summary: This research introduces an attention-based, context-aware multimodal fusion method, leveraging inter-modality inconsistency for sarcasm detection.

### Attention-Based Methods

3. **A Sentiment-Aware Hierarchical Fusion Network for Multimodal Sarcasm Detection**
   - GitHub Link: [Repository link not provided]
   - Summary: This paper presents a sentiment-aware hierarchical fusion network to detect sarcasm by integrating hierarchical features from multiple modalities.

## Datasets

1. **MUStARD (Multimodal Sarcasm Detection Dataset)**
   - GitHub Link: [https://github.com/soujanyaporia/MUStARD?tab=readme-ov-file](https://github.com/soujanyaporia/MUStARD?tab=readme-ov-file)
   - Description: A multimodal dataset designed for sarcasm detection, containing both textual and visual data.

## Current Progress

- **Research and Implementation**: 
  - Currently exploring various fusion techniques and implementing models based on the mentioned research papers.
  - Developing a baseline model for sarcasm detection using the MUStARD dataset.

## Future Work

- **Model Improvement**: 
  - Experimenting with different fusion strategies to enhance model performance.
  - Incorporating more advanced attention mechanisms and context-aware features.

- **Dataset Expansion**: 
  - Collecting and annotating additional multimodal data to enrich the dataset.

## References

- [Multi-modal sarcasm detection based on Multi-Channel Enhanced Fusion model](https://github.com/headacheboy/data-of-multimodal-sarcasm-detection)
- [An Attention-based, Context-aware Multimodal Fusion Method for Sarcasm Detection using Inter-modality Inconsistency](https://github.com/XDU-AI-LYYLab/MultimodalSarcasmDetection)
- [MUStARD Dataset](https://github.com/soujanyaporia/MUStARD?tab=readme-ov-file)
